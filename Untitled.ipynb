{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d26417e9-44a6-41a5-bb53-bddafd566914",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bc69de42-5c36-454e-85ac-4ebe76c91cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_cost_linear_regression(X, y, w, b, lambda_l=1):\n",
    "    '''\n",
    "    Description: computes the cost for regularized linear regression\n",
    "    ( the term with the numerator lambda helps to minimize the size of the parameters \n",
    "    (w1, w2,...),\n",
    "    but I use the version where b is not regularized )\n",
    "    Preconditions: X - m x n matrix which contains our data \n",
    "                    y - m size array - target values\n",
    "                    w - n size array - model parameters\n",
    "                    b - real number - free term parameter\n",
    "                    lambda_l - real number - quantifier for regularization\n",
    "    Postconditons: total_cost - real number - the cost of our calculations, which will help\n",
    "    later to build a better model\n",
    "    '''\n",
    "    m = X.shape[0] # number of input data examples\n",
    "    n = X.shape[1] # number of features of each example\n",
    "\n",
    "    cost = 0\n",
    "    for i in range(m):\n",
    "       f_wb = np.dot(X[i],w)+b # the formula of linear regression model\n",
    "       cost+= (f_wb-y[i])**2 \n",
    "    cost = cost/(2*m)    # until here, we just applied the formula of the cost without regularization\n",
    "\n",
    "    # the regularization part\n",
    "    cost_r = 0\n",
    "    for j in range(n):\n",
    "        cost_r+= w[j]**2\n",
    "    cost_r = (lambda_l/(2*m))* cost_r\n",
    "\n",
    "    # adding the 2 costs\n",
    "    total_cost = cost + cost_r\n",
    "    return total_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fcd0e20d-e678-4dc0-94d8-d91f2ab72d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.48063304  0.17883553 -0.28837188 -0.23445334 -0.00842684]\n",
      "Regularized cost example1: 0.236003117924045\n",
      "[-0.29554775  0.37811744 -0.47261241]\n",
      "Regularized cost example2: 0.1567201382524095\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(1) #running the cost function for some random input data (10 examples with 5 features each)\n",
    "X1 = np.random.rand(10,5) \n",
    "y1 = np.array([0,1,0,0,1,1,1,1,0,1])\n",
    "w1 = np.random.rand(5) - 0.5 \n",
    "print(w1)\n",
    "b1 = 0.5\n",
    "lambda1 = 0.7\n",
    "cost1 = compute_cost_linear_regression(X1, y1, w1, b1, lambda1)\n",
    "\n",
    "print(\"Regularized cost example1:\", cost1)\n",
    "\n",
    "\n",
    "np.random.seed(1)  \n",
    "X2 = np.random.rand(4,3) \n",
    "y2 = np.array([0,1,0,0])\n",
    "w2 = np.random.rand(3) - 0.5\n",
    "print(w2)\n",
    "b2 = 0.5\n",
    "lambda2 = 0.7\n",
    "cost2 = compute_cost_linear_regression(X2, y2, w2, b2, lambda2)\n",
    "\n",
    "print(\"Regularized cost example2:\", cost2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "abc43fca-4c3d-47c0-b3ae-e0500c0eba65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_gradient(X, y, w, b, lambda_l=1):\n",
    "    '''\n",
    "    Description: computes the partial derivative of the w vector and b scalar used in the gradient descent algorithm \n",
    "    Preconditions: X - m x n matrix which contains our data \n",
    "                    y - m size array - target values\n",
    "                    w - n size array - model parameters\n",
    "                    b - real number - free term parameter\n",
    "                    lambda_l - real number - quantifier for regularization\n",
    "    Postconditons: dj_dw - n array (size of w) and dj_db - scalar\n",
    "    '''\n",
    "    m = X.shape[0]\n",
    "    n = X.shape[1]\n",
    "\n",
    "    dj_dw = np.zeros((n,)) # null vector of n size\n",
    "    dj_db = 0\n",
    "    \n",
    "    for i in range(m):\n",
    "        f_wb = np.dot(X[i],w)+b\n",
    "        aux = (f_wb - y[i])\n",
    "        dj_db += aux # forming the derivative of b \n",
    "\n",
    "        # forming the gradient of w - unregularized part for now\n",
    "        for j in range(n):\n",
    "            dj_dw[j] += aux* X[i,j]\n",
    "\n",
    "    dj_dw /= m\n",
    "    dj_db /= m\n",
    "\n",
    "    #now add the regularization part for the w feature vector\n",
    "    for j in range(n):\n",
    "        dj_dw[j] += (lambda_l/m) * w[j]\n",
    "\n",
    "    return dj_db, dj_dw\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8da55e40-4f6b-42a8-a855-7479318c91f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dj_db: 1.1619843967613497\n",
      "dj_dw: [0.71610421 0.69851323 0.56707379 0.52357036]\n"
     ]
    }
   ],
   "source": [
    "# testing the gradient function to see the results\n",
    "np.random.seed(1)\n",
    "X1 = np.random.rand(20,4)\n",
    "y1 = np.array([1,1,0,1,0,1,0,1,0,1,1,1,1,0,0,1,0,1,0,0])\n",
    "w1 = np.random.rand(X1.shape[1])\n",
    "b1 = 0.5\n",
    "lambda1 = 0.7\n",
    "dj_db1, dj_dw1 = compute_gradient(X1, y1, w1, b1, lambda1)\n",
    "\n",
    "print(f\"dj_db: {dj_db1}\")\n",
    "print(f\"dj_dw: {dj_dw1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1a93c0e-b624-48e7-a15c-f61d2169fb04",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
